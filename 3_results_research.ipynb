{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from torch import nn, optim\n",
    "from torch_geometric.nn import LGConv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import utils\n",
    "from models import (\n",
    "    LightGCN,\n",
    "    LightGCNPlus0,\n",
    "    LightGCNPlus1,\n",
    "    LightGCNPlus2,\n",
    "    LightGCNPlus3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'book_crossing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'datasets/{DATASET_NAME}_dataset.bin', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_features = dataset['users_features']\n",
    "items_features = dataset['items_features']\n",
    "train_edge_index = dataset['train_edge_index']\n",
    "val_edge_index = dataset['val_edge_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "LAMBDA = 1e-6\n",
    "BATCH_SIZE = 1024\n",
    "N_BATCH = int(train_edge_index.shape[1]/BATCH_SIZE)\n",
    "N_EPOCHS = 30\n",
    "EMBEDDING_DIMENSION = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "users_features = users_features.to(device)\n",
    "items_features = items_features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = users_features.shape[0]\n",
    "num_items = items_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROJ = torch.rand(users_features.shape[1], EMBEDDING_DIMENSION)\n",
    "ITEM_PROJ = torch.rand(items_features.shape[1], EMBEDDING_DIMENSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_USERS = nn.Embedding(num_embeddings=num_users, embedding_dim=EMBEDDING_DIMENSION)\n",
    "EMB_ITEMS = nn.Embedding(num_embeddings=num_items, embedding_dim=EMBEDDING_DIMENSION)\n",
    "\n",
    "nn.init.normal_(EMB_USERS.weight, std=0.01)\n",
    "nn.init.normal_(EMB_ITEMS.weight, std=0.01);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for i in range(5):\n",
    "    user_proj = torch.rand(users_features.shape[1], EMBEDDING_DIMENSION)\n",
    "    item_proj = torch.rand(items_features.shape[1], EMBEDDING_DIMENSION)\n",
    "    model = LightGCNPlus0(EMB_USERS, EMB_ITEMS, users_features, items_features, user_proj, item_proj).to(device)\n",
    "    result = utils.training_routine(\n",
    "        model,\n",
    "        f'LightGCN+ (solution 0) [{i}]',\n",
    "        DATASET_NAME,\n",
    "        train_edge_index,\n",
    "        val_edge_index,\n",
    "        N_EPOCHS,\n",
    "        N_BATCH,\n",
    "        BATCH_SIZE,\n",
    "        LAMBDA,\n",
    "        K\n",
    "    )\n",
    "    results_list.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "for i, result in enumerate(results_list):\n",
    "    label = f'LightGCN+ (solution 0) [run {i}]'\n",
    "    ax[0].plot(result['val_recall'], label=label)\n",
    "    ax[1].plot(result['val_ndcg'], label=label)\n",
    "    ax[0].set_title('Validation Recall@20', fontweight='bold')\n",
    "    ax[1].set_title('Validation NDCG@20', fontweight='bold')\n",
    "    for i in range(2):\n",
    "        ax[i].set_xlabel('epoch', fontweight='bold')\n",
    "        ax[i].set_ylabel('value', fontweight='bold')\n",
    "        ax[i].legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    'LightGCN': LightGCN(EMB_USERS, EMB_ITEMS),\n",
    "    'LightGCN+_scenario_0': LightGCNPlus0(EMB_USERS, EMB_ITEMS, users_features, items_features, USER_PROJ, ITEM_PROJ),\n",
    "    'LightGCN+_scenario_1': LightGCNPlus1(EMB_USERS, EMB_ITEMS, users_features, items_features, USER_PROJ, ITEM_PROJ),\n",
    "    'LightGCN+_scenario_2': LightGCNPlus2(EMB_USERS, EMB_ITEMS, users_features, items_features, USER_PROJ, ITEM_PROJ),\n",
    "    'LightGCN+_scenario_3': LightGCNPlus3(EMB_USERS, EMB_ITEMS, users_features, items_features, USER_PROJ, ITEM_PROJ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS['LightGCN'].load_state_dict(\n",
    "    torch.load(f'models/final/{DATASET_NAME}_LightGCN.bin', weights_only=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS['LightGCN+_scenario_0'].load_state_dict(\n",
    "    torch.load(f'models/final/{DATASET_NAME}_LightGCN+_scenario_0.bin', weights_only=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS['LightGCN+_scenario_1'].load_state_dict(\n",
    "    torch.load(f'models/final/{DATASET_NAME}_LightGCN+_scenario_1.bin', weights_only=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS['LightGCN+_scenario_2'].load_state_dict(\n",
    "    torch.load(f'models/final/{DATASET_NAME}_LightGCN+_scenario_2.bin', weights_only=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS['LightGCN+_scenario_3'].load_state_dict(\n",
    "    torch.load(f'models/final/{DATASET_NAME}_LightGCN+_scenario_3.bin', weights_only=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d = {}\n",
    "\n",
    "for model_name, model in MODELS.items():\n",
    "    print(model_name)\n",
    "    emb_users, emb_items = model.forward(val_edge_index)\n",
    "    emb_users = emb_users.cpu().detach().numpy()\n",
    "    emb_items = emb_items.cpu().detach().numpy()\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    emb_users_2d = tsne.fit_transform(emb_users)\n",
    "    emb_items_2d = tsne.fit_transform(emb_items)\n",
    "    embeddings_2d[model_name] = (emb_users_2d, emb_items_2d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = list(MODELS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(14, 6))\n",
    "\n",
    "for i in range(5):\n",
    "    x = embeddings_2d[model_names[i]][0][:, 0]\n",
    "    y = embeddings_2d[model_names[i]][0][:, 1]\n",
    "    axs[0, i].scatter(x, y, s=0.5, alpha=0.7)\n",
    "    axs[0, i].set_title(model_names[i].replace('_', ' '), fontweight='bold', fontsize=12)\n",
    "    for axis in ['x', 'y']:\n",
    "        axs[0, i].tick_params(axis=axis, labelsize=10)\n",
    "    if i == 0:\n",
    "        axs[0, i].set_ylabel('user embeddings', fontweight='bold', fontsize=12)\n",
    "\n",
    "for j in range(5):\n",
    "    x = embeddings_2d[model_names[j]][1][:, 0]\n",
    "    y = embeddings_2d[model_names[j]][1][:, 1]\n",
    "    axs[1, j].scatter(x, y, s=0.5, alpha=0.7)\n",
    "    for axis in ['x', 'y']:\n",
    "        axs[1, j].tick_params(axis=axis, labelsize=10)\n",
    "    if j == 0:\n",
    "        axs[1, j].set_ylabel('item embeddings', fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projections_list.append((\n",
    "    MODELS['LightGCN+_scenario_0'].users_features_proj.cpu().detach().numpy(),\n",
    "    MODELS['LightGCN+_scenario_0'].items_features_proj.cpu().detach().numpy()\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODELS['LightGCN+_scenario_1']\n",
    "projections_list.append((\n",
    "    (model.users_features_proj * nn.functional.sigmoid(model.alpha_users)).cpu().detach().numpy(),\n",
    "    (model.items_features_proj * nn.functional.sigmoid(model.alpha_items)).cpu().detach().numpy()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODELS['LightGCN+_scenario_2']\n",
    "projections_list.append((\n",
    "    (model.users_features_proj * nn.functional.sigmoid(model.users_coefs_vector)).cpu().detach().numpy(),\n",
    "    (model.items_features_proj * nn.functional.sigmoid(model.items_coefs_vector)).cpu().detach().numpy()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MODELS['LightGCN+_scenario_3']\n",
    "projections_list.append((\n",
    "    model.user_proj(model.users_features).cpu().detach().numpy(),\n",
    "    model.item_proj(model.items_features).cpu().detach().numpy()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_min, user_max = float('inf'), float('-inf')\n",
    "item_min, item_max = float('inf'), float('-inf')\n",
    "\n",
    "for user_proj, item_proj in projections_list:\n",
    "    user_min, user_max = min(user_min, user_proj.min()), max(user_max, user_proj.max())\n",
    "    item_min, item_max = min(item_min, item_proj.min()), max(item_max, item_proj.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 4, figsize=(14, 6))\n",
    "\n",
    "for i in range(4):\n",
    "    im1 = axs[0, i].imshow(projections_list[i][0].T, aspect='auto', cmap='cool')\n",
    "    axs[0, i].set_title(model_names[i+1].replace('_', ' '), fontweight='bold', fontsize=12)\n",
    "    if i == 0:\n",
    "        axs[0, i].set_ylabel('user projection matrix', fontweight='bold', fontsize=12)\n",
    "    fig.colorbar(im1, ax=axs[0, i], fraction=0.046, pad=0.04)\n",
    "\n",
    "for j in range(4):\n",
    "    im1 = axs[1, j].imshow(projections_list[j][1].T, aspect='auto', cmap='cool')\n",
    "    if j == 0:\n",
    "        axs[1, j].set_ylabel('item projection matrix', fontweight='bold', fontsize=12)\n",
    "    fig.colorbar(im1, ax=axs[1, j], fraction=0.046, pad=0.04)\n",
    "    \n",
    "plt.grid(False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(projections_list[0][0].T[:, :1000], aspect='auto', cmap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
